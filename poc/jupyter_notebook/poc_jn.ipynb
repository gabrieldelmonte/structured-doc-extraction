{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1713ebfe",
   "metadata": {},
   "source": [
    "# Prova de conceito utilizando modelo **winninghealth/olmOCR-2-7B-1025-INT4**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf802975",
   "metadata": {},
   "source": [
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c777a0",
   "metadata": {},
   "source": [
    "Observação: este notebook foi inteiramente projetado para ser executado no ambiente Google Colab!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8a512",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0090c",
   "metadata": {},
   "source": [
    "## Instalação de dependências\n",
    "\n",
    "Instalação das bibliotecas necessárias para o projeto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847bb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y poppler-utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install auto-round\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e794f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install json-repair pdf2image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd53cd6",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas\n",
    "\n",
    "Importação de todas as bibliotecas necessárias para processamento de imagens, PDFs e inferência do modelo\n",
    "\n",
    "- `Transformers`: para carregar o modelo pré-treinado e o tokenizador\n",
    "- `Torch`: para manipulação de tensores e operações relacionadas a deep learning\n",
    "- `PIL (Python Imaging Library)`: para manipulação e processamento de imagens\n",
    "- `pdf2image`: para converter páginas de PDF em imagens\n",
    "- `json_repair`: para reparar arquivos JSON corrompidos\n",
    "- `json`: para manipulação de arquivos JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee486a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from pdf2image import convert_from_path\n",
    "from json_repair import repair_json\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import base64\n",
    "import torch\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f286d",
   "metadata": {},
   "source": [
    "## Carregando o modelo\n",
    "\n",
    "Carregando o modelo olmOCR-2-7B quantizado e seu processador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\n",
    "    'winninghealth/olmOCR-2-7B-1025-INT4'\n",
    ")\n",
    "print('Processor loaded successfully!')\n",
    "\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    'winninghealth/olmOCR-2-7B-1025-INT4',\n",
    "    device_map = 'auto'\n",
    ")\n",
    "print('Model loaded successfully!')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3c1aa",
   "metadata": {},
   "source": [
    "## Funções de pré-processamento\n",
    "\n",
    "Funções para redimensionar imagens e converter PDFs em imagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, max_size = 1200):\n",
    "    \"\"\"\n",
    "    Resize image maintaining aspect ratio with maximum dimension of max_size pixels.\n",
    "\n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        max_size: Maximum dimension in pixels (default: 1200)\n",
    "\n",
    "    Returns:\n",
    "        PIL Image object resized\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "\n",
    "    if width <= max_size and height <= max_size:\n",
    "        return image\n",
    "\n",
    "    if width > height:\n",
    "        new_width = max_size\n",
    "        new_height = int((max_size / width) * height)\n",
    "    else:\n",
    "        new_height = max_size\n",
    "        new_width = int((max_size / height) * width)\n",
    "\n",
    "    return image.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, max_size = 1200):\n",
    "    \"\"\"\n",
    "    Convert PDF pages to images and resize them.\n",
    "\n",
    "    Args:\n",
    "        pdf_path: Path to PDF file\n",
    "        max_size: Maximum dimension in pixels for each page (default: 1200)\n",
    "\n",
    "    Returns:\n",
    "        List of PIL Image objects, one per page\n",
    "    \"\"\"\n",
    "    images = convert_from_path(pdf_path)\n",
    "    resized_images = [resize_image(img, max_size) for img in images]\n",
    "\n",
    "    return resized_images\n",
    "\n",
    "\n",
    "def image_to_base64(image):\n",
    "    \"\"\"\n",
    "    Convert PIL Image to base64 string.\n",
    "\n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "    \n",
    "    Returns:\n",
    "        Base64 encoded string\n",
    "    \"\"\"\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format = 'PNG')\n",
    "\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db65a177",
   "metadata": {},
   "source": [
    "## Função de inferência\n",
    "\n",
    "Função principal para processar imagens e extrair informações estruturadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structured_info(image, processor, model, device):\n",
    "    \"\"\"\n",
    "    Extract structured information from an image using the OCR model.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        processor: Model processor\n",
    "        model: Vision2Seq model\n",
    "        device: Device to run inference on\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with extracted information\n",
    "    \"\"\"\n",
    "    image_base64 = image_to_base64(image)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'text', 'text': 'Extract structured information from this image in JSON format.'},\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/png;base64,{image_base64}'}},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(messages, tokenize = False, add_generation_prompt = True)\n",
    "    main_image = Image.open(BytesIO(base64.b64decode(image_base64)))\n",
    "\n",
    "    inputs = processor(\n",
    "        text = [text],\n",
    "        images = [main_image],\n",
    "        padding = True,\n",
    "        return_tensors = 'pt',\n",
    "    )\n",
    "    inputs = {key: value.to(device) for (key, value) in inputs.items()}\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        temperature = 0.1,\n",
    "        max_new_tokens = 8192, # This value NEEDS to be adjusted based on expected output size!\n",
    "        num_return_sequences = 1,\n",
    "        do_sample = True,\n",
    "    )\n",
    "\n",
    "    prompt_length = inputs['input_ids'].shape[1]\n",
    "    new_tokens = output[:, prompt_length:]\n",
    "    text_output = processor.tokenizer.batch_decode(\n",
    "        new_tokens,\n",
    "        skip_special_tokens = True\n",
    "    )\n",
    "\n",
    "    return parse_json_output(text_output[0])\n",
    "\n",
    "\n",
    "def parse_json_output(raw_output):\n",
    "    \"\"\"\n",
    "    Parse and repair JSON output from model.\n",
    "    \n",
    "    Args:\n",
    "        raw_output: Raw string output from model\n",
    "    \n",
    "    Returns:\n",
    "        Parsed JSON dictionary\n",
    "    \"\"\"\n",
    "    raw_text = raw_output.replace('```json', '').replace('```', '').strip()\n",
    "    fixed_json = repair_json(raw_text)\n",
    "\n",
    "    return json.loads(fixed_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266387c6",
   "metadata": {},
   "source": [
    "## Função principal de processamento\n",
    "\n",
    "Função que processa diferentes tipos de documentos (imagens e PDFs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5dd05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(file_path, processor, model, device, max_size = 1200):\n",
    "    \"\"\"\n",
    "    Process a document (image or PDF) and extract structured information.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to document file\n",
    "        processor: Model processor\n",
    "        model: Vision2Seq model\n",
    "        device: Device to run inference on\n",
    "        max_size: Maximum image dimension in pixels\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with extracted information\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    file_extension = file_path.suffix.lower()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if file_extension == '.pdf':\n",
    "        print(f'Processing PDF: {file_path.name}')\n",
    "        images = convert_pdf_to_images(str(file_path), max_size)\n",
    "\n",
    "        results = {}\n",
    "        for idx, image in enumerate(images, 1):\n",
    "            print(f'  Processing page {idx}/{len(images)}...')\n",
    "            page_start = time.time()\n",
    "\n",
    "            page_data = extract_structured_info(image, processor, model, device)\n",
    "            results[f\"page_{idx:02d}\"] = page_data\n",
    "\n",
    "            page_time = time.time() - page_start\n",
    "            print(f'  Page {idx} completed in {page_time:.2f} seconds')\n",
    "\n",
    "        result = {'pdf': results}\n",
    "\n",
    "    elif file_extension in ['.jpg', '.jpeg', '.png']:\n",
    "        print(f'Processing image: {file_path.name}')\n",
    "\n",
    "        image = Image.open(file_path)\n",
    "        resized_image = resize_image(image, max_size)\n",
    "        \n",
    "        result = extract_structured_info(resized_image, processor, model, device)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f'Unsupported file format: {file_extension}')\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f'Total processing time: {total_time:.2f} seconds\\n')\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e92945d",
   "metadata": {},
   "source": [
    "## Processamento dos documentos\n",
    "\n",
    "Processamento de todos os documentos fornecidos para o desafio técnico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d09999",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path('data_challenge')\n",
    "documents = [\n",
    "    data_folder / 'case_01_drivers_license.jpeg',\n",
    "    data_folder / 'case_02_bill.jpg',\n",
    "    data_folder / 'case_03_large_document.pdf'\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for doc_path in documents:\n",
    "    if doc_path.exists():\n",
    "        print(f'{\"=\"*60}')\n",
    "        result = process_document(doc_path, processor, model, device)\n",
    "        all_results[doc_path.stem] = result\n",
    "    else:\n",
    "        print(f'File not found: {doc_path}')\n",
    "\n",
    "print(f'{\"=\"*60}')\n",
    "print('All documents processed successfully!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae38a63",
   "metadata": {},
   "source": [
    "## Visualização dos resultados\n",
    "\n",
    "Exibição dos resultados extraídos de cada documento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_name, result in all_results.items():\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Document: {doc_name}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    print(json.dumps(result, indent = 4, ensure_ascii = False))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926108ea",
   "metadata": {},
   "source": [
    "## Salvando os resultados\n",
    "\n",
    "Salvando os resultados em arquivos JSON individuais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d13579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = Path('data_challenge/results')\n",
    "output_folder.mkdir(exist_ok = True)\n",
    "\n",
    "for doc_name, result in all_results.items():\n",
    "    output_file = output_folder / f'{doc_name}_result.json'\n",
    "    with open(output_file, 'w', encoding = 'utf-8') as f:\n",
    "        json.dump(result, f, indent = 4, ensure_ascii = False)\n",
    "    print(f'Saved: {output_file}')\n",
    "\n",
    "print('\\nAll results saved successfully!')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
