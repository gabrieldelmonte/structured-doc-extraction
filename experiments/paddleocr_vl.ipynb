{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3964caad",
   "metadata": {},
   "source": [
    "# PaddleOCR-VL - Experimento com modelo multilíngue de OCR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804922f",
   "metadata": {},
   "source": [
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51241441",
   "metadata": {},
   "source": [
    "Este notebook demonstra o uso do modelo **PaddleOCR-VL** para extração de texto de imagens através de OCR multilíngue\n",
    "\n",
    "## Sobre o experimento\n",
    "\n",
    "- **Modelo**: PaddlePaddle/PaddleOCR-VL\n",
    "- **Objetivo**: Realizar OCR (Optical Character Recognition) e outras tarefas de reconhecimento em imagens e documentos\n",
    "- **Ambiente**: Google Colab com GPU T4\n",
    "\n",
    "## Configuração inicial\n",
    "\n",
    "Primeiro, vamos instalar todas as dependências necessárias usando o `uv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv package manager\n",
    "!pip install -q uv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11115b3",
   "metadata": {},
   "source": [
    "### Instalação das dependências principais\n",
    "\n",
    "Agora vamos instalar todas as bibliotecas necessárias:\n",
    "- **PyTorch**: Framework de deep learning\n",
    "- **Transformers**: Biblioteca da Hugging Face para modelos de linguagem\n",
    "- **Pillow**: Para processamento de imagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462f50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core dependencies with specific versions\n",
    "!uv pip install transformers==4.57.1 pillow torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85e1eb",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f77b646",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas\n",
    "\n",
    "Agora vamos importar todas as bibliotecas necessárias para o experimento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7da3d91",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3efb54",
   "metadata": {},
   "source": [
    "## Carregando o modelo\n",
    "\n",
    "Vamos carregar o modelo **PaddleOCR-VL** e o processador correspondente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357567c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = 'cuda'\n",
    "\n",
    "# Model configuration\n",
    "model_path = 'PaddlePaddle/PaddleOCR-VL'\n",
    "\n",
    "print('=' * 70)\n",
    "print('CARREGANDO MODELO PADDLEOCR-VL')\n",
    "print(f'\\nModelo: {model_path}')\n",
    "print('=' * 70)\n",
    "\n",
    "print('\\nCarregando modelo...')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code = True,\n",
    "    torch_dtype = torch.bfloat16\n",
    ").to(device).eval()\n",
    "print('Modelo carregado com sucesso!')\n",
    "\n",
    "print('\\nCarregando processador...')\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code = True\n",
    ")\n",
    "print('Processador carregado com sucesso!')\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print(f'Dispositivo: {next(model.parameters()).device}')\n",
    "print(f'Tipo de dados: {next(model.parameters()).dtype}')\n",
    "print('=' * 70 + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36005610",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c62bfa",
   "metadata": {},
   "source": [
    "## Configuração dos parâmetros\n",
    "\n",
    "Vamos configurar os caminhos das imagens e os parametros para o processamento\n",
    "\n",
    "### Tarefas disponíveis:\n",
    "\n",
    "O PaddleOCR-VL suporta multiplas tarefas de reconhecimento:\n",
    "\n",
    "| Tarefa        | Descrição                                 | Prompt                    |\n",
    "|---------------|-------------------------------------------|---------------------------|\n",
    "| **OCR**       | Reconhecimento óptico de caracteres       | `OCR:`                    |\n",
    "| **Table**     | Reconhecimento de estrutura de tabelas    | `Table Recognition:`      |\n",
    "| **Chart**     | Reconhecimento de gráficos e diagramas    | `Chart Recognition:`      |\n",
    "| **Formula**   | Reconhecimento de fórmulas matemáticas    | `Formula Recognition:`    |\n",
    "\n",
    "Neste experimento, vamos usar a tarefa **OCR** para extração de texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fca38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task configuration\n",
    "chosen_task = 'ocr'  # Options: 'ocr' | 'table' | 'chart' | 'formula'\n",
    "\n",
    "prompts = {\n",
    "    'ocr': 'OCR:',\n",
    "    'table': 'Table Recognition:',\n",
    "    'formula': 'Formula Recognition:',\n",
    "    'chart': 'Chart Recognition:',\n",
    "}\n",
    "\n",
    "# File paths\n",
    "base_path = ''\n",
    "image_path = os.path.join(base_path, 'data_experiments', 'case_01_drivers_license.jpeg')\n",
    "\n",
    "print('CONFIGURAÇÃO DO EXPERIMENTO')\n",
    "print('=' * 70)\n",
    "print(f'Tarefa escolhida: {chosen_task.upper()}')\n",
    "print(f'Prompt: {prompts[chosen_task]}')\n",
    "print(f'\\nArquivo de entrada: {image_path}')\n",
    "print('=' * 70 + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b027fd",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554beff3",
   "metadata": {},
   "source": [
    "## Processamento de OCR\n",
    "\n",
    "Agora vamos processar a imagem e extrair o texto usando o modelo PaddleOCR-VL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e37887",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '=' * 70)\n",
    "print('INICIANDO PROCESSAMENTO')\n",
    "print('=' * 70 + '\\n')\n",
    "\n",
    "# Process the image\n",
    "if not os.path.exists(image_path):\n",
    "    print(f'Erro: arquivo de imagem não encontrado: {image_path}')\n",
    "else:\n",
    "    print(f'Processando imagem: {os.path.basename(image_path)}')\n",
    "    print('-' * 70)\n",
    "\n",
    "    try:\n",
    "        # Load the image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        # Prepare messages for the model\n",
    "        messages = [\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': [\n",
    "                    {'type': 'image', 'image': image},\n",
    "                    {'type': 'text', 'text': prompts[chosen_task]},\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        print('\\nPreparando entrada para o modelo...')\n",
    "        inputs = processor.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize = True,\n",
    "            add_generation_prompt = True,\n",
    "            return_dict = True,\n",
    "            return_tensors = 'pt'\n",
    "        ).to(device)\n",
    "\n",
    "        print('Executando inferência do modelo...')\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Run inference\n",
    "        outputs = model.generate(**inputs, max_new_tokens=1024)\n",
    "        result = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "        end_time = time.time()\n",
    "        inference_time = end_time - start_time\n",
    "\n",
    "        print(f'Inferência concluida!')\n",
    "        print(f'Tempo de processamento: {inference_time:.2f} segundos')\n",
    "\n",
    "        print('\\n' + '=' * 70)\n",
    "        print('RESULTADO')\n",
    "        print('=' * 70)\n",
    "        print(result)\n",
    "        print('=' * 70)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'\\nErro ao processar {os.path.basename(image_path)}: {str(e)}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('PROCESSAMENTO CONCLUÍDO!')\n",
    "print('=' * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8917e",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c27eae",
   "metadata": {},
   "source": [
    "## Informações adicionais\n",
    "\n",
    "### Sobre o modelo PaddleOCR-VL\n",
    "\n",
    "O **PaddleOCR-VL** é um modelo de visão e linguagem desenvolvido pela PaddlePaddle capaz de realizar múltiplas tarefas de reconhecimento em documentos:\n",
    "\n",
    "- **OCR multilíngue**: suporta reconhecimento de texto em multiplos idiomas\n",
    "- **Reconhecimento de tabelas**: extrai estrutura e conteúdo de tabelas\n",
    "- **Reconhecimento de fórmulas**: converte fórmulas matemáticas em LaTeX\n",
    "- **Reconhecimento de gráficos**: analisa e extrai informações de gráficos e diagramas\n",
    "\n",
    "### Tarefas suportadas\n",
    "\n",
    "O modelo aceita diferentes prompts para diferentes tarefas:\n",
    "\n",
    "1. **OCR**: `OCR:`\n",
    "   - Extração de texto geral de imagens\n",
    "   - Suporte multilíngue\n",
    "\n",
    "2. **Table Recognition**: `Table Recognition:`\n",
    "   - Reconhecimento de estrutura de tabelas\n",
    "   - Extração de dados tabulares\n",
    "\n",
    "3. **Formula Recognition**: `Formula Recognition:`\n",
    "   - Conversão de fórmulas matemáticas para LaTeX\n",
    "   - Suporta equações complexas\n",
    "\n",
    "4. **Chart Recognition**: `Chart Recognition:`\n",
    "   - Análise de gráficos gerais\n",
    "   - Extração de dados e labels\n",
    "\n",
    "### Configuração do modelo\n",
    "\n",
    "- **max_new_tokens**: 1024 - número maximo de tokens gerados\n",
    "- **torch_dtype**: bfloat16 - precisão brain float 16 para otimizar memória\n",
    "- **trust_remote_code**: True - permite executar código customizado do modelo\n",
    "\n",
    "### Requisitos recomendados de hardware\n",
    "\n",
    "- GPU NVIDIA com CUDA\n",
    "- Aproximadamente 8-10GB de VRAM\n",
    "- Também pode rodar em CPU, mas será significativamente mais lento\n",
    "\n",
    "### Vantagens do PaddleOCR-VL\n",
    "\n",
    "- Modelo multilíngue com suporte a diversos idiomas\n",
    "- Múltiplas tarefas em um único modelo\n",
    "- Baseado em arquitetura Vision-Language moderna\n",
    "- Boa precisão em documentos complexos\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
